# World Models

Literature and resources for 2018 paper *World Models* - David Ha, Jürgen Schmidhuber.

- original paper code base - [hardmaru/WorldModelsExperiments](https://github.com/hardmaru/WorldModelsExperiments) - [advice on running the code base](http://blog.otoro.net/2018/06/09/world-models-experiments/) 
- [interactive blog post](https://worldmodels.github.io/) - World Models
- [2018 paper](https://arxiv.org/pdf/1809.01999.pdf) - Recurrent World Models Facilitate Policy Evolution
- [2018 paper](https://arxiv.org/pdf/1803.10122.pdf) - World Models
- [David Ha talk at NIPS](https://youtu.be/HzA8LRqhujk) - Recurrent World Models Facilitate Policy Evolution

## VAE

[Convolutional Variational Autoencoder - TensorFlow tutorial (MNIST)](https://www.tensorflow.org/tutorials/generative/cvae)

[Tutorial - What is a variational autoencoder? - JAAN ALTOSAAR](https://jaan.io/what-is-variational-autoencoder-vae-tutorial/)

## Memory

[Mixture Density Networks with TensorFlow](http://blog.otoro.net/2015/11/24/mixture-density-networks-with-tensorflow/)

[A Hitchhiker’s Guide to Mixture Density Networks](https://towardsdatascience.com/a-hitchhikers-guide-to-mixture-density-networks-76b435826cca)

[Understanding LSTM Networks - colah's blog](https://colah.github.io/posts/2015-08-Understanding-LSTMs/)

## CMA-ES

[CMA-ES - Wikipedia](https://en.wikipedia.org/wiki/CMA-ES)

[A Visual Guide to Evolution Strategies](http://blog.otoro.net/2017/10/29/visual-evolution-strategies/).

[Evolving Stable Strategies](http://blog.otoro.net/2017/11/12/evolving-stable-strategies/).

[hardmaru/estool](https://github.com/hardmaru/estool)

[The CMA Evolution Strategy](http://cma.gforge.inria.fr/)

[Hansen (2016) The CMA Evolution Strategy: A Tutorial](https://arxiv.org/pdf/1604.00772.pdf)

[Hansen (2004) Random Search](http://www.cmap.polytechnique.fr/~nikolaus.hansen/searchandcmaslides.pdf)

[Test functions for optimization - Wikipedia](https://en.wikipedia.org/wiki/Test_functions_for_optimization)

[Salimans et. al (2017) Evolution Strategies as a Scalable Alternative to Reinforcement Learning](https://arxiv.org/pdf/1703.03864.pdf) - [blog post](https://openai.com/blog/evolution-strategies/) - [github](https://github.com/openai/evolution-strategies-starter)

[pycma](https://github.com/CMA-ES/pycma)

## more VAE

http://gregorygundersen.com/blog/2018/04/29/reparameterization/

https://towardsdatascience.com/understanding-variational-autoencoders-vaes-f70510919f73 (bit on reparameterization)

[Intuitively Understanding Variational Autoencoders - Irhum Shafkat](https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf)

https://jaan.io/what-is-variational-autoencoder-vae-tutorial/ (point out in referesces!)

https://stats.stackexchange.com/questions/288451/why-is-mean-squared-error-the-cross-entropy-between-the-empirical-distribution-a/288453

https://arxiv.org/pdf/1907.08956.pdf

https://www.shakirm.com/papers/VITutorial.pdf

https://stats.stackexchange.com/questions/288451/why-is-mean-squared-error-the-cross-entropy-between-the-empirical-distribution-a/288453

https://deepgenerativemodels.github.io/notes/vae/
https://en.wikipedia.org/wiki/Discriminative_model
